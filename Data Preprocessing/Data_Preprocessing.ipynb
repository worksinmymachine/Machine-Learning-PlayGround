{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "_RaKx8QMwsip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "RXrI53Xfw0Ro"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Dataset**"
      ],
      "metadata": {
        "id": "_UoWj2vgw97F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv('Data.csv')\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7weluVQxB64",
        "outputId": "3ef38a05-efe3-4f6e-cc64-fcb6af3f5078"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Country   Age   Salary Purchased\n",
            "0   France  44.0  72000.0        No\n",
            "1    Spain  27.0  48000.0       Yes\n",
            "2  Germany  30.0  54000.0        No\n",
            "3    Spain  38.0  61000.0        No\n",
            "4  Germany  40.0      NaN       Yes\n",
            "5   France  35.0  58000.0       Yes\n",
            "6    Spain   NaN  52000.0        No\n",
            "7   France  48.0  79000.0       Yes\n",
            "8  Germany  50.0  83000.0        No\n",
            "9   France  37.0  67000.0       Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=dataset.iloc[:, :-1].values\n",
        "y=dataset.iloc[:,-1].values\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awuldAG5xNNZ",
        "outputId": "6d4fc267-e289-4c4d-fa86-7e123a065546"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can see that there are some missing values (nan) .You may end up building\n",
        "# a biased machine learning model, leading to incorrect results if the missing\n",
        "# values are not handled properly."
      ],
      "metadata": {
        "id": "knlYpIQMx9v4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling missing values**"
      ],
      "metadata": {
        "id": "Y9GP2rheyGrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#how to handle missing values?\n",
        "# 1. Imputation\n",
        "# 2. Deletion\n",
        "# Imputation-\n",
        "#   1. Mean Imputation\n",
        "#   2. Median Imputation\n",
        "# Deletion- remove rows/cols with missing values"
      ],
      "metadata": {
        "id": "_-jZGuW0yK9h"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
        "imputer.fit(x[:,1:3])\n",
        "x[:, 1:3] = imputer.transform(x[:, 1:3])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuOQdE56yfqp",
        "outputId": "d55ffd39-eb78-4e72-d543-63b92f1c09fd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding Categorical Variables**"
      ],
      "metadata": {
        "id": "rSMoXl2K0AEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since most machine learning models only accept numerical variables,\n",
        "# preprocessing the categorical variables becomes a necessary step. We need to\n",
        "# convert these categorical variables to numbers such that the model is able to\n",
        "# understand and extract valuable information.\n",
        "\n",
        "\n",
        "#Encoding is mostly done on the columns of Data"
      ],
      "metadata": {
        "id": "jdcOW3VN0QTg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding independent variables\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# One Hot Encoding is a way of encoding categorical variable to binary vectors\n",
        "# should be used when you are not concerned with implied order/rank\n",
        "ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough')\n",
        "x=ct.fit_transform(x)\n",
        "# since we need x (independent features) for training & testing the model , it needs to be a np array . Hence\n",
        "x=np.array(x)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Wty91O0miJ",
        "outputId": "57a5c91e-e239-4b55-f27d-f79aca5a5135"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoding - Label Encoding is a technique that is used to convert\n",
        "# categorical columns into numerical ones so that they can be fitted by machine\n",
        "# learning models which only take numerical data. It is an important\n",
        "# pre-processing step in a machine-learning project. %% Encoding dependent\n",
        "# variables\n",
        "\n",
        "# Label Encoder maintains order/rank"
      ],
      "metadata": {
        "id": "PMBjlY-C2iF6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding dependent variables\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "y=le.fit_transform(y)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_wKgi4o2C7F",
        "outputId": "29ae9f0c-8516-4b03-ddc1-0a58d0178ea1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data into training set & test set**"
      ],
      "metadata": {
        "id": "fvXPVns53Ndm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n"
      ],
      "metadata": {
        "id": "kYq7dfyM3STX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lutc2MUi3vie",
        "outputId": "f1f320ab-fd71-4f88-bee8-ab0d20c58e6a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ob4FHfh3v8O",
        "outputId": "9b13ef75-92ee-4fa8-bbf7-fcae7da9d45c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUtkfWh73wFr",
        "outputId": "12763734-eca2-41a0-e103-ea3d4b58816c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqTrGyIw3wOB",
        "outputId": "851632aa-66f9-46af-f933-6943a6e96c6c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**"
      ],
      "metadata": {
        "id": "ZPbuBST838f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling is a data preprocessing technique used to transform the values\n",
        "# of features or variables in a dataset to a similar scale. The purpose is to\n",
        "# ensure that all features contribute equally to the model and to avoid the\n",
        "# domination of features with larger values."
      ],
      "metadata": {
        "id": "8WS8XI2b4AWk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "# make sure that only the features that need scaling are scaled.\n",
        "#Here we do not have any such constraint .\n",
        "# However remember that not all features need scaling\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "# for test data we do not need to fit it to the model as test data is used for prediction\n",
        "x_test = scaler.transform(x_test)\n"
      ],
      "metadata": {
        "id": "oRJNmaHT5imj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Scaled x_train\",x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFjW_Pp26KtM",
        "outputId": "6327c0cd-c7c6-47ff-b6e2-458d2484bf01"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled x_train [[-0.77459667 -0.57735027  1.29099445 -0.19159184 -1.07812594]\n",
            " [-0.77459667  1.73205081 -0.77459667 -0.01411729 -0.07013168]\n",
            " [ 1.29099445 -0.57735027 -0.77459667  0.56670851  0.63356243]\n",
            " [-0.77459667 -0.57735027  1.29099445 -0.30453019 -0.30786617]\n",
            " [-0.77459667 -0.57735027  1.29099445 -1.90180114 -1.42046362]\n",
            " [ 1.29099445 -0.57735027 -0.77459667  1.14753431  1.23265336]\n",
            " [-0.77459667  1.73205081 -0.77459667  1.43794721  1.57499104]\n",
            " [ 1.29099445 -0.57735027 -0.77459667 -0.74014954 -0.56461943]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_test \",x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTnE3xLm6L7S",
        "outputId": "0e4dc485-da74-4288-cb95-08c3b8c1b678"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test  [[-0.77459667  1.73205081 -0.77459667 -1.46618179 -0.9069571 ]\n",
            " [ 1.29099445 -0.57735027 -0.77459667 -0.44973664  0.20564034]]\n"
          ]
        }
      ]
    }
  ]
}